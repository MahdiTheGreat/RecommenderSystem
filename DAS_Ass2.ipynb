{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiTheGreat/RecommenderSystem/blob/main/DAS_Ass2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq ipdb\n",
        "import ipdb"
      ],
      "metadata": {
        "id": "I1-GiECSpfkm",
        "outputId": "d838ec7d-49e0-469a-b986-0af9686d10dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hAutomatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb on"
      ],
      "metadata": {
        "id": "EVl2MpVvp6BU",
        "outputId": "6718832b-ccda-41b8-f7ad-9e8dfeec0c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MahdiTheGreat/RecommenderSystem.git\n",
        "%cd RecommenderSystem\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OaXiRcnfrW3",
        "outputId": "9c08dfb1-19d6-4df1-be06-e76be6e911ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RecommenderSystem'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 6), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (16/16), 147.54 KiB | 1.97 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "/content/RecommenderSystem\n",
            "DAS_Ass2.ipynb  movie_reviews.zip  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"movie_reviews.zip\" -d \"DAS_Ass2\"\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Htd1DFkf8qy",
        "outputId": "dfaaf824-03b1-490b-9904-551f0b11e5a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  movie_reviews.zip\n",
            "  inflating: DAS_Ass2/movie_genres.csv  \n",
            "  inflating: DAS_Ass2/user_reviews.csv  \n",
            "\u001b[0m\u001b[01;34mDAS_Ass2\u001b[0m/  DAS_Ass2.ipynb  movie_reviews.zip  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#content filtering\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# File paths\n",
        "movie_genres_path = \"DAS_Ass2/movie_genres.csv\"\n",
        "user_reviews_path = \"DAS_Ass2/user_reviews.csv\"\n",
        "\n",
        "### STEP 1: Load Data\n",
        "# Load movie genre data (X)\n",
        "movie_genres_df = pd.read_csv(movie_genres_path)\n",
        "\n",
        "# Load user review data (Y)\n",
        "user_reviews_df = pd.read_csv(user_reviews_path)\n",
        "\n",
        "### STEP 2: Data Cleaning\n",
        "# Remove non-numeric columns\n",
        "X = movie_genres_df.iloc[:, 2:].to_numpy()  # Drop movie index and title, keep genre features\n",
        "Y = user_reviews_df.iloc[:, 2:].to_numpy()  # Drop user index and name, keep ratings\n",
        "\n",
        "### STEP 3: Replace Missing Ratings (0s with NaN for clarity)\n",
        "Y = Y.astype(np.float64)  # Change the data type of Y to float\n",
        "Y[Y == 0] = np.nan  # This makes it easier to handle missing data\n",
        "\n",
        "### STEP 4: Display Matrix Shapes\n",
        "print(f\"X Shape (Movies × Features): {X.shape}\")\n",
        "print(f\"Y Shape (Users × Movies): {Y.shape}\")\n",
        "\n",
        "### Optional: Display a small sample of the cleaned matrices\n",
        "print(\"Sample X (Movie Features):\")\n",
        "print(X[:5, :])  # First 5 movies, all features\n",
        "\n",
        "print(\"Sample Y (User Ratings):\")\n",
        "print(Y[:5, :5])  # First 5 users, first 5 movies\n",
        "\n",
        "# Store user preference vectors\n",
        "Theta = np.zeros((len(Y), X.shape[1]))\n",
        "print(f\"Theta Shape (Users × Features): {Theta.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BArDP82Ap17w",
        "outputId": "cd9fa9e4-f03d-4f4a-ef5a-b485597d9d87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Shape (Movies × Features): (2000, 25)\n",
            "Y Shape (Users × Movies): (600, 2000)\n",
            "Sample X (Movie Features):\n",
            "[[1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            " [0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]]\n",
            "Sample Y (User Ratings):\n",
            "[[nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]]\n",
            "Theta Shape (Users × Features): (600, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Define lambda values to tune\n",
        "lambda_values = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Iterate over the first 5 users\n",
        "for user_id in range(len(Y)):\n",
        "    # Get user ratings (Y row)\n",
        "    y_user = Y[user_id, :]  # Ratings given by this user (some are NaN)\n",
        "\n",
        "    # Find rated movies (i.e., non-NaN values)\n",
        "    rated_movies = ~np.isnan(y_user)\n",
        "\n",
        "    # If the user has rated at least one movie, train the model\n",
        "    if np.sum(rated_movies) > 0:\n",
        "        # Extract features (X) and corresponding ratings (y) for rated movies\n",
        "        X_train = X[rated_movies, :]\n",
        "        y_train = y_user[rated_movies]\n",
        "\n",
        "        # Train Ridge regression with cross-validation to find the best λ\n",
        "        ridge_model = RidgeCV(alphas=lambda_values, store_cv_values=True)\n",
        "        ridge_model.fit(X_train, y_train)\n",
        "\n",
        "        # Store learned user preferences (Θ)\n",
        "        Theta[user_id, :] = ridge_model.coef_\n",
        "\n"
      ],
      "metadata": {
        "id": "Dac99gWOj29l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommended_movies(Y_pred,top_k=5,users_num=5):\n",
        " Y_pred[np.where(~np.isnan(Y[:len(Y), :]))] = -np.inf\n",
        " if users_num is None:\n",
        "     users_num = len(Y_pred)\n",
        " # Recommend top 5 movies for each of the first 5 users\n",
        " recommendations = np.argsort(-Y_pred, axis=1)[:, :top_k]  # Sort descending\n",
        "\n",
        " # Convert movie indices to actual movie titles\n",
        " recommended_movies = []\n",
        " for user_id in range(users_num):\n",
        "     recommended_movies.append(movie_genres_df.iloc[recommendations[user_id], 1].values)\n",
        "\n",
        " # Extract user names from the original dataset\n",
        " user_names = user_reviews_df.iloc[:users_num, 1].values\n",
        "\n",
        " # Display recommendations with user names\n",
        " for user_id in range(users_num):\n",
        "     print(f\"\\n🔹 **{user_names[user_id]} should watch:**\")\n",
        "     for movie in recommended_movies[user_id]:\n",
        "         print(f\"   🎬 {movie}\")\n",
        " return recommendations"
      ],
      "metadata": {
        "id": "8Hrc2JKWeFdl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict ratings for all movies\n",
        "Y_pred = Theta @ X.T  # Matrix multiplication ΘX^T\n",
        "\n",
        "# Mask out already rated movies (to avoid recommending watched ones)\n",
        "Y_pred[np.where(~np.isnan(Y[:len(Y), :]))] = -np.inf\n",
        "\n",
        "recommendations=recommended_movies(Y_pred,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAYBGcMbneDL",
        "outputId": "0233cdfa-3563-4653-e6f5-8f6cebd35e8d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 **Vincent should watch:**\n",
            "   🎬 Evolution\n",
            "   🎬 What the #$*! Do We (K)now!?\n",
            "   🎬 Dark City\n",
            "   🎬 The Returned\n",
            "   🎬 The Unborn\n",
            "\n",
            "🔹 **Edgar should watch:**\n",
            "   🎬 Alpha and Omega 4: The Legend of the Saw Toothed Cave\n",
            "   🎬 The Magic Sword: Quest for Camelot\n",
            "   🎬 Stargate: The Ark of Truth\n",
            "   🎬 9\n",
            "   🎬 Centurion\n",
            "\n",
            "🔹 **Addilyn should watch:**\n",
            "   🎬 Alvin and the Chipmunks: Chipwrecked\n",
            "   🎬 Alvin and the Chipmunks: The Road Chip\n",
            "   🎬 Alvin and the Chipmunks\n",
            "   🎬 Hannah Montana: The Movie\n",
            "   🎬 Spice World\n",
            "\n",
            "🔹 **Marlee should watch:**\n",
            "   🎬 Zodiac\n",
            "   🎬 Suspect Zero\n",
            "   🎬 Gone Girl\n",
            "   🎬 Narc\n",
            "   🎬 Regression\n",
            "\n",
            "🔹 **Javier should watch:**\n",
            "   🎬 Hannah Montana: The Movie\n",
            "   🎬 Sinbad: Legend of the Seven Seas\n",
            "   🎬 Lilo & Stitch\n",
            "   🎬 The Last Song\n",
            "   🎬 Mrs. Doubtfire\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#collaborative filtering\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Replace missing values (NaNs) with the user’s average rating for better SVD performance\n",
        "Y_filled = np.copy(Y)\n",
        "for i in range(Y.shape[0]):  # Loop over users\n",
        "    user_mean = np.nanmean(Y[i, :])  # Compute mean rating for user i\n",
        "    Y_filled[i, np.isnan(Y[i, :])] = user_mean  # Replace NaN with mean rating\n",
        "\n",
        "# Create a mask for known ratings (not NaN)\n",
        "known_ratings = ~np.isnan(Y)\n",
        "\n",
        "# Create training set: Copy Y and hide 20% of ratings for validation\n",
        "Y_train = np.copy(Y_filled)\n",
        "num_hidden = int(0.2 * np.sum(known_ratings))  # 20% of known ratings\n",
        "\n",
        "# Randomly select indices to hide\n",
        "hidden_indices = np.argwhere(known_ratings)\n",
        "np.random.shuffle(hidden_indices)\n",
        "hidden_indices = hidden_indices[:num_hidden]\n",
        "true_ratings = Y[hidden_indices[:, 0], hidden_indices[:, 1]]\n",
        "\n",
        "# Hide ratings in Y_train for validation\n",
        "for i, j in hidden_indices:\n",
        "    Y_train[i, j] = np.nan\n"
      ],
      "metadata": {
        "id": "m5L1nvGJPXqG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Truncated SVD to factorize Y into two low-rank matrices\n",
        "svd = TruncatedSVD(n_components=10)\n",
        "Theta = svd.fit_transform(Y_filled)  # User preferences (Users × Latent Features)\n",
        "X = svd.components_.T  # Movie features (Movies × Latent Features)\n",
        "\n",
        "# Predict ratings for all users and movies\n",
        "Y_pred = Theta @ X.T  # Matrix multiplication to reconstruct predicted ratings\n",
        "\n",
        "# Mask out already rated movies (avoid recommending watched ones)\n",
        "predicted_ratings = Y_pred[hidden_indices[:, 0], hidden_indices[:, 1]]\n",
        "rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
        "accuracy=accuracy_score(true_ratings, np.round(predicted_ratings))\n",
        "\n",
        "print(f\"For content filtering with latent factor model: RMSE = {rmse:.4f},accuracy = {accuracy:.4f}\")\n",
        "\n",
        "recommendations=recommended_movies(Y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqxlgy5m7ETi",
        "outputId": "186820bb-058f-48fb-962f-3342084ea798"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For content filtering with latent factor model: RMSE = 1.1005,accuracy = 0.3141\n",
            "\n",
            "🔹 **Vincent should watch:**\n",
            "   🎬 Loser\n",
            "   🎬 Gigli\n",
            "   🎬 Beneath the Planet of the Apes\n",
            "   🎬 Shark Tale\n",
            "   🎬 Serenity\n",
            "\n",
            "🔹 **Edgar should watch:**\n",
            "   🎬 Perrier's Bounty\n",
            "   🎬 The Magic Sword: Quest for Camelot\n",
            "   🎬 Punch-Drunk Love\n",
            "   🎬 Zipper\n",
            "   🎬 Mongol: The Rise of Genghis Khan\n",
            "\n",
            "🔹 **Addilyn should watch:**\n",
            "   🎬 Perrier's Bounty\n",
            "   🎬 The Lost Skeleton of Cadavra\n",
            "   🎬 Loser\n",
            "   🎬 Torque\n",
            "   🎬 A Simple Plan\n",
            "\n",
            "🔹 **Marlee should watch:**\n",
            "   🎬 World War Z\n",
            "   🎬 The Good Thief\n",
            "   🎬 Gigli\n",
            "   🎬 Max Payne\n",
            "   🎬 Cheap Thrills\n",
            "\n",
            "🔹 **Javier should watch:**\n",
            "   🎬 Gigli\n",
            "   🎬 The Other End of the Line\n",
            "   🎬 Confidence\n",
            "   🎬 Final Fantasy: The Spirits Within\n",
            "   🎬 A Cinderella Story\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collaborative Filtering with Optimized k using SVD\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import mean_squared_error,accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Range of k values to test\n",
        "k_values = list(range(5, 100, 5))  # This will create a list from 1 to 100, stepping by 5\n",
        "\n",
        "\n",
        "# Store RMSE values for different k\n",
        "rmse_scores = []\n",
        "accuracy_scores=[]\n",
        "\n",
        "for k in k_values:\n",
        "    svd = TruncatedSVD(n_components=k)\n",
        "    Theta = svd.fit_transform(Y_filled)\n",
        "    X = svd.components_.T  # Movies × Features\n",
        "\n",
        "    # Predict missing ratings\n",
        "    Y_pred = Theta @ X.T\n",
        "\n",
        "    # Compute RMSE on the hidden ratings\n",
        "    true_ratings = Y[hidden_indices[:, 0], hidden_indices[:, 1]]\n",
        "    predicted_ratings = Y_pred[hidden_indices[:, 0], hidden_indices[:, 1]]\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
        "    rmse_scores.append(rmse)\n",
        "\n",
        "    accuracy=accuracy_score(true_ratings, np.round(predicted_ratings))\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "    print(f\"🔹 For k = {k}, RMSE = {rmse:.4f},accuracy = {accuracy:.4f}\")\n",
        "\n",
        "# Find the best k (minimum RMSE)\n",
        "best_k = k_values[np.argmin(rmse_scores)]\n",
        "print(f\"\\n✅ Best k: {best_k} with RMSE = {min(rmse_scores):.4f}\")\n",
        "\n",
        "### STEP 5: Train Final Model with Best k\n",
        "\n",
        "# Apply Truncated SVD with the best k\n",
        "svd_final = TruncatedSVD(n_components=best_k)\n",
        "Theta = svd_final.fit_transform(Y_filled)\n",
        "X = svd_final.components_.T  # Movie features (Movies × Latent Features)\n",
        "\n",
        "# Predict ratings for all users and movies\n",
        "Y_pred = Theta @ X.T  # Matrix multiplication to reconstruct predicted ratings\n",
        "\n",
        "recommendations=recommended_movies(Y_pred)"
      ],
      "metadata": {
        "id": "2nSwwCZHWJLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a502a47-7526-4327-f293-49a2c0fd3fd2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 For k = 5, RMSE = 1.1227,accuracy = 0.3095\n",
            "🔹 For k = 10, RMSE = 1.0996,accuracy = 0.3126\n",
            "🔹 For k = 15, RMSE = 1.0776,accuracy = 0.3180\n",
            "🔹 For k = 20, RMSE = 1.0563,accuracy = 0.3289\n",
            "🔹 For k = 25, RMSE = 1.0370,accuracy = 0.3325\n",
            "🔹 For k = 30, RMSE = 1.0192,accuracy = 0.3392\n",
            "🔹 For k = 35, RMSE = 0.9998,accuracy = 0.3467\n",
            "🔹 For k = 40, RMSE = 0.9813,accuracy = 0.3531\n",
            "🔹 For k = 45, RMSE = 0.9627,accuracy = 0.3625\n",
            "🔹 For k = 50, RMSE = 0.9463,accuracy = 0.3661\n",
            "🔹 For k = 55, RMSE = 0.9283,accuracy = 0.3749\n",
            "🔹 For k = 60, RMSE = 0.9116,accuracy = 0.3788\n",
            "🔹 For k = 65, RMSE = 0.8955,accuracy = 0.3891\n",
            "🔹 For k = 70, RMSE = 0.8798,accuracy = 0.3994\n",
            "🔹 For k = 75, RMSE = 0.8646,accuracy = 0.4064\n",
            "🔹 For k = 80, RMSE = 0.8487,accuracy = 0.4182\n",
            "🔹 For k = 85, RMSE = 0.8325,accuracy = 0.4230\n",
            "🔹 For k = 90, RMSE = 0.8195,accuracy = 0.4309\n",
            "🔹 For k = 95, RMSE = 0.8047,accuracy = 0.4411\n",
            "\n",
            "✅ Best k: 95 with RMSE = 0.8047\n",
            "\n",
            "🔹 **Vincent should watch:**\n",
            "   🎬 Happy Gilmore\n",
            "   🎬 Cheap Thrills\n",
            "   🎬 Knight and Day\n",
            "   🎬 Head Over Heels\n",
            "   🎬 Elysium\n",
            "\n",
            "🔹 **Edgar should watch:**\n",
            "   🎬 Hoffa\n",
            "   🎬 Hardball\n",
            "   🎬 Pirates of the Caribbean: Dead Man's Chest\n",
            "   🎬 Punch-Drunk Love\n",
            "   🎬 Ghosts of Mars\n",
            "\n",
            "🔹 **Addilyn should watch:**\n",
            "   🎬 The Order\n",
            "   🎬 She Wore a Yellow Ribbon\n",
            "   🎬 Maid in Manhattan\n",
            "   🎬 Morning Glory\n",
            "   🎬 Perrier's Bounty\n",
            "\n",
            "🔹 **Marlee should watch:**\n",
            "   🎬 Swordfish\n",
            "   🎬 Open Season\n",
            "   🎬 Inception\n",
            "   🎬 Molière\n",
            "   🎬 Scary Movie 3\n",
            "\n",
            "🔹 **Javier should watch:**\n",
            "   🎬 Frozen\n",
            "   🎬 Truth or Die\n",
            "   🎬 The Phantom\n",
            "   🎬 Soul Survivors\n",
            "   🎬 Unbroken\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "num_users, num_movies = Y.shape\n",
        "\n",
        "# Compute Baseline Ratings (b_ui) = User Average Ratings\n",
        "user_means  = np.nanmean(Y, axis=1)\n",
        "b_ui = np.tile(user_means[:, np.newaxis], num_movies)  # Broadcast for all movies\n",
        "\n",
        "# Compute Similarity Matrix Using KNN (User-User Similarity)\n",
        "knn = NearestNeighbors(metric='cosine', n_neighbors=2, algorithm='brute')  # Find 2 nearest users\n",
        "knn.fit(Y_filled)\n",
        "\n",
        "# Function to Predict Rating for User u on Movie i\n",
        "def predict_rating(knn_model, u, i, k=2):\n",
        "    if not np.isnan(Y[u, i]):  # If already rated, return the actual rating\n",
        "        return Y[u, i]\n",
        "\n",
        "    # Find k nearest users (excluding self)\n",
        "    distances, neighbors = knn.kneighbors(Y[u].reshape(1, -1), n_neighbors=k+1)\n",
        "    neighbors = neighbors.flatten()[1:]  # Exclude self\n",
        "\n",
        "    # Compute similarity scores (convert cosine distances to similarities)\n",
        "    s_ij = 1 - distances.flatten()[1:]\n",
        "\n",
        "    # Compute weighted rating adjustment\n",
        "    numerator = sum(s_ij[j] * (Y[neighbors[j], i] - b_ui[neighbors[j], i]) for j in range(len(neighbors)) if Y[neighbors[j], i] != 0)\n",
        "    denominator = sum(abs(s_ij[j]) for j in range(len(neighbors)) if Y[neighbors[j], i] != 0)\n",
        "\n",
        "    ipdb.set_trace()\n",
        "    print(\"numerator: \",numerator)\n",
        "    print(\"denominator: \",denominator)\n",
        "    print(\"s_ij: \",s_ij)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if denominator == 0:\n",
        "        return b_ui[u, i]  # Default to baseline\n",
        "\n",
        "    print(\"b_ui: \",b_ui[u, i])\n",
        "\n",
        "    return b_ui[u, i] + (numerator / denominator)\n",
        "\n",
        "# Example: Predict rating for User 1 on Movie 3 (Indexing starts at 0)\n",
        "predicted_rating = predict_rating(knn, 20, 6)\n",
        "print(f\"Predicted Rating: {predicted_rating}\")"
      ],
      "metadata": {
        "id": "CTuwNbygCppf",
        "outputId": "321b4cf9-5fec-43da-9fe5-edd0cff3f2ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-ac62c3c29fda>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Example: Predict rating for User 1 on Movie 3 (Indexing starts at 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mpredicted_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_rating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted Rating: {predicted_rating}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-ac62c3c29fda>\u001b[0m in \u001b[0;36mpredict_rating\u001b[0;34m(knn_model, u, i, k)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Find k nearest users (excluding self)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Exclude self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_precomputed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 X = validate_data(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nNearestNeighbors does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m(169)\u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    167 \u001b[0;31m                \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    168 \u001b[0;31m            )\n",
            "\u001b[0m\u001b[0;32m--> 169 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    170 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    171 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "--KeyboardInterrupt--\n",
            "\n",
            "KeyboardInterrupt: Interrupted by user\n"
          ]
        }
      ]
    }
  ]
}